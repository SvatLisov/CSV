{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1cb906d6",
      "metadata": {
        "id": "1cb906d6"
      },
      "source": [
        "1. Из наборов изображений, выбрать по 135 изображений каждой цифры без шума: a)100/15/20 для обучающей/валидационной/тестовой выборок). В каждой выборке должно содержаться равное количество изображений каждой цифры в вертикальном и горизонтальном положении соответственно.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "19979cd3",
      "metadata": {
        "id": "19979cd3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "\n",
        "nb_images = 700  # Количество изображений каждой цифры\n",
        "# Создание папок для тренировочной и тестовой выборок\n",
        "train_dir = f'train_data_{nb_images}/train'\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "\n",
        "def create_directory(dir_name):\n",
        "    if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name)\n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    os.makedirs(os.path.join(dir_name, \"0\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"1\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"3\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"8\"))\n",
        "\n",
        "create_directory(train_dir)\n",
        "\n",
        "# Функция для генерации изображений\n",
        "def generate_images(digits, num_images, directory):\n",
        "    for i in range(num_images):\n",
        "        # Создание белого фона\n",
        "        img = Image.new('L', (100, 100), color='white')\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Создание изображения цифры\n",
        "        digit_img = Image.new('L', (20, 50), color='white')\n",
        "        digit_draw = ImageDraw.Draw(digit_img)\n",
        "        digit_draw.text((0, 0), str(digit), fill='black')\n",
        "\n",
        "        # Случайное местоположение цифры\n",
        "        x = random.randint(0, 80)\n",
        "        y = random.randint(0, 50)\n",
        "        img.paste(digit_img, (x, y))\n",
        "\n",
        "        # Поворот изображения (вертикально или горизонтально)\n",
        "        if i % 2:\n",
        "            img = img.transpose(Image.ROTATE_90)\n",
        "\n",
        "        # Преобразование изображения PIL в изображение OpenCV\n",
        "        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Сохранение изображения\n",
        "        cv2.imwrite(os.path.join(f'{directory}', f'{digit}_{i}.png'), cv_img)\n",
        "\n",
        "# Генерация изображений для тренировочной выборки\n",
        "for digit in [0, 1, 3, 8]:\n",
        "  generate_images([0, 1, 3, 8], nb_images, f'{train_dir}/{digit}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a3728568",
      "metadata": {
        "id": "a3728568"
      },
      "outputs": [],
      "source": [
        "test_dir = 'test_data_1'\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "def create_directory(dir_name):\n",
        "    #if os.path.exists(dir_name):\n",
        "       # shutil.rmtree(dir_name)\n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    os.makedirs(os.path.join(dir_name, \"0\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"1\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"3\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"8\"))\n",
        "\n",
        "create_directory(test_dir)\n",
        "\n",
        "# Функция для генерации изображений\n",
        "def generate_images(digits, num_images, directory):\n",
        "    for i in range(num_images):\n",
        "        # Создание белого фона\n",
        "        img = Image.new('L', (100, 100), color='white')\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Создание изображения цифры\n",
        "        digit_img = Image.new('L', (20, 50), color='white')\n",
        "        digit_draw = ImageDraw.Draw(digit_img)\n",
        "        digit_draw.text((0, 0), str(digit), fill='black')\n",
        "\n",
        "        # Случайное местоположение цифры\n",
        "        x = random.randint(0, 80)\n",
        "        y = random.randint(0, 50)\n",
        "        img.paste(digit_img, (x, y))\n",
        "\n",
        "        # Поворот изображения (вертикально или горизонтально)\n",
        "        if i % 2:\n",
        "            img = img.transpose(Image.ROTATE_90)\n",
        "\n",
        "        # Преобразование изображения PIL в изображение OpenCV\n",
        "        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Сохранение изображения\n",
        "        cv2.imwrite(os.path.join(f'{directory}', f'{digit}_{i}.png'), cv_img)\n",
        "\n",
        "# Генерация изображений для тестовой выборки\n",
        "for digit in [0, 1, 3, 8]:\n",
        "  generate_images([0, 1, 3, 8], 20, f'{test_dir}/{digit}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "42c020be",
      "metadata": {
        "id": "42c020be"
      },
      "outputs": [],
      "source": [
        "nb_images = 700  # Количество изображений каждой цифры\n",
        "val_nb_images = 100  # Количество изображений каждой цифры\n",
        "# Создание папок для тренировочной и тестовой выборок\n",
        "val_dir = f'train_data_{nb_images}/val'\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "def create_directory(dir_name):\n",
        "    #if os.path.exists(dir_name):\n",
        "        #shutil.rmtree(dir_name)\n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    os.makedirs(os.path.join(dir_name, \"0\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"1\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"3\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"8\"))\n",
        "\n",
        "create_directory(val_dir)\n",
        "\n",
        "# Функция для генерации изображений\n",
        "def generate_images(digits, num_images, directory):\n",
        "    for i in range(num_images):\n",
        "        # Создание белого фона\n",
        "        img = Image.new('L', (100, 100), color='white')\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Создание изображения цифры\n",
        "        digit_img = Image.new('L', (20, 50), color='white')\n",
        "        digit_draw = ImageDraw.Draw(digit_img)\n",
        "        digit_draw.text((0, 0), str(digit), fill='black')\n",
        "\n",
        "        # Случайное местоположение цифры\n",
        "        x = random.randint(0, 80)\n",
        "        y = random.randint(0, 50)\n",
        "        img.paste(digit_img, (x, y))\n",
        "\n",
        "        # Поворот изображения (вертикально или горизонтально)\n",
        "        if i % 2:\n",
        "            img = img.transpose(Image.ROTATE_90)\n",
        "\n",
        "        # Преобразование изображения PIL в изображение OpenCV\n",
        "        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Сохранение изображения\n",
        "        cv2.imwrite(os.path.join(f'{directory}', f'{digit}_{i}.png'), cv_img)\n",
        "\n",
        "# Генерация изображений для тренировочной выборки\n",
        "for digit in [0, 1, 3, 8]:\n",
        "  generate_images([0, 1, 3, 8], val_nb_images, f'{val_dir}/{digit}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16aed5e3",
      "metadata": {
        "id": "16aed5e3"
      },
      "source": [
        "2. Реализовать каждую из сверточных нейронных сетей https://keras.io/api/applications/: Xception, ResNet152V2, InceptionResNetV2, DenseNet201, NASNetLarge и вывести результаты классификации на тестовом множестве.\n",
        "3. Повторить пункт 2, изменив размеры обучающей/валидационной/тестовой выборок для каждой цифры на:\n",
        "    * b) 250/30/20,\n",
        "    * c) 400/60/20,\n",
        "    * d) 700/100/20.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f85988fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f85988fc",
        "outputId": "55f460d3-03be-4b07-a35c-2b2efe1789ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2800 images belonging to 4 classes.\n",
            "Found 400 images belonging to 4 classes.\n",
            "Found 80 images belonging to 4 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n",
            "\n",
            "Training Xception...\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 14s 69ms/step - loss: 0.8503 - accuracy: 0.6404 - val_loss: 0.6060 - val_accuracy: 0.7375\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 0.5275 - accuracy: 0.7761 - val_loss: 0.5054 - val_accuracy: 0.7800\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 0.4308 - accuracy: 0.8136 - val_loss: 0.4783 - val_accuracy: 0.7550\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 0.3980 - accuracy: 0.8254 - val_loss: 0.4062 - val_accuracy: 0.8150\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 0.3568 - accuracy: 0.8475 - val_loss: 0.4009 - val_accuracy: 0.8025\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 0.3165 - accuracy: 0.8668 - val_loss: 0.3770 - val_accuracy: 0.8275\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 0.3049 - accuracy: 0.8718 - val_loss: 0.3767 - val_accuracy: 0.8300\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 0.2886 - accuracy: 0.8768 - val_loss: 0.3553 - val_accuracy: 0.8375\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 0.2690 - accuracy: 0.8850 - val_loss: 0.3554 - val_accuracy: 0.8425\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 0.2558 - accuracy: 0.8936 - val_loss: 0.3793 - val_accuracy: 0.8125\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 0.2305 - accuracy: 0.9039 - val_loss: 0.3635 - val_accuracy: 0.8250\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 0.2210 - accuracy: 0.9104 - val_loss: 0.3618 - val_accuracy: 0.8350\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 0.2095 - accuracy: 0.9143 - val_loss: 0.3455 - val_accuracy: 0.8375\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 0.1980 - accuracy: 0.9214 - val_loss: 0.3841 - val_accuracy: 0.8125\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 0.1940 - accuracy: 0.9268 - val_loss: 0.3417 - val_accuracy: 0.8350\n",
            "\n",
            "Evaluating Xception on test data...\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.3247 - accuracy: 0.8375\n",
            "Test Accuracy: 0.8374999761581421\n",
            "3/3 [==============================] - 1s 39ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[20  0  0  0]\n",
            " [ 0 20  0  0]\n",
            " [ 0  0 12  8]\n",
            " [ 1  0  4 15]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98        20\n",
            "           1       1.00      1.00      1.00        20\n",
            "           3       0.75      0.60      0.67        20\n",
            "           8       0.65      0.75      0.70        20\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.84      0.84      0.83        80\n",
            "weighted avg       0.84      0.84      0.83        80\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234545216/234545216 [==============================] - 1s 0us/step\n",
            "\n",
            "Training ResNet152V2...\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 23s 135ms/step - loss: 0.8285 - accuracy: 0.6500 - val_loss: 0.5616 - val_accuracy: 0.7850\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 8s 87ms/step - loss: 0.5277 - accuracy: 0.7675 - val_loss: 0.5427 - val_accuracy: 0.7575\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 8s 91ms/step - loss: 0.4692 - accuracy: 0.7975 - val_loss: 0.5271 - val_accuracy: 0.7825\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 8s 92ms/step - loss: 0.4269 - accuracy: 0.8118 - val_loss: 0.5255 - val_accuracy: 0.7750\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 8s 87ms/step - loss: 0.3937 - accuracy: 0.8304 - val_loss: 0.4416 - val_accuracy: 0.8150\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 8s 90ms/step - loss: 0.3498 - accuracy: 0.8575 - val_loss: 0.3833 - val_accuracy: 0.8425\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 8s 89ms/step - loss: 0.3132 - accuracy: 0.8654 - val_loss: 0.4134 - val_accuracy: 0.8100\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 8s 86ms/step - loss: 0.3392 - accuracy: 0.8529 - val_loss: 0.4126 - val_accuracy: 0.8225\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 8s 88ms/step - loss: 0.2801 - accuracy: 0.8889 - val_loss: 0.4159 - val_accuracy: 0.8150\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 8s 86ms/step - loss: 0.2903 - accuracy: 0.8750 - val_loss: 0.4578 - val_accuracy: 0.8175\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 8s 86ms/step - loss: 0.2636 - accuracy: 0.8875 - val_loss: 0.4492 - val_accuracy: 0.8300\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 8s 92ms/step - loss: 0.2523 - accuracy: 0.8939 - val_loss: 0.4336 - val_accuracy: 0.8125\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 8s 91ms/step - loss: 0.2484 - accuracy: 0.9000 - val_loss: 0.3843 - val_accuracy: 0.8525\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 8s 87ms/step - loss: 0.1890 - accuracy: 0.9250 - val_loss: 0.3918 - val_accuracy: 0.8350\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 8s 87ms/step - loss: 0.2090 - accuracy: 0.9161 - val_loss: 0.4199 - val_accuracy: 0.8250\n",
            "\n",
            "Evaluating ResNet152V2 on test data...\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.5189 - accuracy: 0.7875\n",
            "Test Accuracy: 0.7875000238418579\n",
            "3/3 [==============================] - 3s 97ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[17  0  0  3]\n",
            " [ 0 20  0  0]\n",
            " [ 1  0 18  1]\n",
            " [ 6  0  6  8]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.85      0.77        20\n",
            "           1       1.00      1.00      1.00        20\n",
            "           3       0.75      0.90      0.82        20\n",
            "           8       0.67      0.40      0.50        20\n",
            "\n",
            "    accuracy                           0.79        80\n",
            "   macro avg       0.78      0.79      0.77        80\n",
            "weighted avg       0.78      0.79      0.77        80\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219055592/219055592 [==============================] - 2s 0us/step\n",
            "\n",
            "Training InceptionResNetV2...\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 21s 106ms/step - loss: 0.9358 - accuracy: 0.5696 - val_loss: 0.8533 - val_accuracy: 0.6250\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 4s 47ms/step - loss: 0.7302 - accuracy: 0.6789 - val_loss: 0.7295 - val_accuracy: 0.6750\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.6643 - accuracy: 0.6979 - val_loss: 0.6770 - val_accuracy: 0.6850\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 4s 50ms/step - loss: 0.6210 - accuracy: 0.7257 - val_loss: 0.7492 - val_accuracy: 0.6875\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 5s 52ms/step - loss: 0.5939 - accuracy: 0.7339 - val_loss: 0.6896 - val_accuracy: 0.6750\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 0.5682 - accuracy: 0.7418 - val_loss: 0.6775 - val_accuracy: 0.7025\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 5s 54ms/step - loss: 0.5382 - accuracy: 0.7575 - val_loss: 0.6797 - val_accuracy: 0.7075\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 4s 47ms/step - loss: 0.5202 - accuracy: 0.7629 - val_loss: 0.6926 - val_accuracy: 0.7050\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 0.5013 - accuracy: 0.7732 - val_loss: 0.7211 - val_accuracy: 0.7100\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 5s 53ms/step - loss: 0.4877 - accuracy: 0.7814 - val_loss: 0.7036 - val_accuracy: 0.7025\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 4s 47ms/step - loss: 0.4903 - accuracy: 0.7779 - val_loss: 0.7363 - val_accuracy: 0.6950\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 0.4643 - accuracy: 0.7896 - val_loss: 0.7601 - val_accuracy: 0.7250\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 5s 55ms/step - loss: 0.4548 - accuracy: 0.7957 - val_loss: 0.8335 - val_accuracy: 0.6975\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 4s 47ms/step - loss: 0.4451 - accuracy: 0.8046 - val_loss: 0.7204 - val_accuracy: 0.7150\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 0.4286 - accuracy: 0.8107 - val_loss: 0.7058 - val_accuracy: 0.7250\n",
            "\n",
            "Evaluating InceptionResNetV2 on test data...\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.7230 - accuracy: 0.7000\n",
            "Test Accuracy: 0.699999988079071\n",
            "3/3 [==============================] - 4s 59ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[15  3  0  2]\n",
            " [ 1 19  0  0]\n",
            " [ 2  4 10  4]\n",
            " [ 4  3  1 12]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.75      0.71        20\n",
            "           1       0.66      0.95      0.78        20\n",
            "           3       0.91      0.50      0.65        20\n",
            "           8       0.67      0.60      0.63        20\n",
            "\n",
            "    accuracy                           0.70        80\n",
            "   macro avg       0.73      0.70      0.69        80\n",
            "weighted avg       0.73      0.70      0.69        80\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74836368/74836368 [==============================] - 0s 0us/step\n",
            "\n",
            "Training DenseNet201...\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 26s 135ms/step - loss: 0.6480 - accuracy: 0.7196 - val_loss: 0.4853 - val_accuracy: 0.7675\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 6s 63ms/step - loss: 0.3787 - accuracy: 0.8332 - val_loss: 0.3027 - val_accuracy: 0.8800\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 5s 55ms/step - loss: 0.3014 - accuracy: 0.8686 - val_loss: 0.2949 - val_accuracy: 0.8725\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 5s 59ms/step - loss: 0.2581 - accuracy: 0.8964 - val_loss: 0.3194 - val_accuracy: 0.8675\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 5s 60ms/step - loss: 0.2477 - accuracy: 0.8989 - val_loss: 0.2138 - val_accuracy: 0.9300\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 5s 56ms/step - loss: 0.2167 - accuracy: 0.9075 - val_loss: 0.2002 - val_accuracy: 0.9200\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 5s 62ms/step - loss: 0.1884 - accuracy: 0.9239 - val_loss: 0.2024 - val_accuracy: 0.9350\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.1612 - accuracy: 0.9396 - val_loss: 0.2023 - val_accuracy: 0.9325\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 5s 58ms/step - loss: 0.1494 - accuracy: 0.9464 - val_loss: 0.2814 - val_accuracy: 0.8800\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 5s 55ms/step - loss: 0.1557 - accuracy: 0.9382 - val_loss: 0.1716 - val_accuracy: 0.9375\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.1284 - accuracy: 0.9500 - val_loss: 0.1628 - val_accuracy: 0.9425\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 5s 55ms/step - loss: 0.1383 - accuracy: 0.9443 - val_loss: 0.1788 - val_accuracy: 0.9225\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 5s 55ms/step - loss: 0.1354 - accuracy: 0.9471 - val_loss: 0.1509 - val_accuracy: 0.9550\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 5s 61ms/step - loss: 0.1377 - accuracy: 0.9361 - val_loss: 0.1503 - val_accuracy: 0.9500\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 5s 54ms/step - loss: 0.1228 - accuracy: 0.9500 - val_loss: 0.2208 - val_accuracy: 0.9125\n",
            "\n",
            "Evaluating DenseNet201 on test data...\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1241 - accuracy: 0.9625\n",
            "Test Accuracy: 0.9624999761581421\n",
            "3/3 [==============================] - 5s 74ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[20  0  0  0]\n",
            " [ 0 20  0  0]\n",
            " [ 0  0 20  0]\n",
            " [ 0  0  3 17]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        20\n",
            "           1       1.00      1.00      1.00        20\n",
            "           3       0.87      1.00      0.93        20\n",
            "           8       1.00      0.85      0.92        20\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.97      0.96      0.96        80\n",
            "weighted avg       0.97      0.96      0.96        80\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n",
            "343610240/343610240 [==============================] - 4s 0us/step\n",
            "\n",
            "Training NASNetLarge...\n",
            "Epoch 1/15\n",
            "88/88 [==============================] - 40s 233ms/step - loss: 0.8631 - accuracy: 0.6304 - val_loss: 0.5968 - val_accuracy: 0.7325\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 13s 152ms/step - loss: 0.5458 - accuracy: 0.7621 - val_loss: 0.4611 - val_accuracy: 0.8150\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 13s 151ms/step - loss: 0.4646 - accuracy: 0.7989 - val_loss: 0.4348 - val_accuracy: 0.7975\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 13s 148ms/step - loss: 0.4021 - accuracy: 0.8207 - val_loss: 0.4355 - val_accuracy: 0.8225\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 13s 150ms/step - loss: 0.3669 - accuracy: 0.8450 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 13s 147ms/step - loss: 0.3272 - accuracy: 0.8604 - val_loss: 0.3768 - val_accuracy: 0.8450\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 13s 146ms/step - loss: 0.2939 - accuracy: 0.8811 - val_loss: 0.3291 - val_accuracy: 0.8625\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 13s 147ms/step - loss: 0.2642 - accuracy: 0.8964 - val_loss: 0.3061 - val_accuracy: 0.8925\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 14s 160ms/step - loss: 0.2438 - accuracy: 0.9071 - val_loss: 0.3373 - val_accuracy: 0.8450\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 13s 147ms/step - loss: 0.2263 - accuracy: 0.9089 - val_loss: 0.3047 - val_accuracy: 0.8825\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 13s 150ms/step - loss: 0.2050 - accuracy: 0.9232 - val_loss: 0.3202 - val_accuracy: 0.8650\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 13s 147ms/step - loss: 0.1861 - accuracy: 0.9325 - val_loss: 0.3006 - val_accuracy: 0.8800\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 13s 147ms/step - loss: 0.1740 - accuracy: 0.9404 - val_loss: 0.3386 - val_accuracy: 0.8650\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 13s 147ms/step - loss: 0.1678 - accuracy: 0.9386 - val_loss: 0.3064 - val_accuracy: 0.8925\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 13s 146ms/step - loss: 0.1448 - accuracy: 0.9496 - val_loss: 0.2972 - val_accuracy: 0.8875\n",
            "\n",
            "Evaluating NASNetLarge on test data...\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 0.1794 - accuracy: 0.9125\n",
            "Test Accuracy: 0.9125000238418579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78074864ea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 6s 140ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[20  0  0  0]\n",
            " [ 0 20  0  0]\n",
            " [ 0  0 16  4]\n",
            " [ 0  0  3 17]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        20\n",
            "           1       1.00      1.00      1.00        20\n",
            "           3       0.84      0.80      0.82        20\n",
            "           8       0.81      0.85      0.83        20\n",
            "\n",
            "    accuracy                           0.91        80\n",
            "   macro avg       0.91      0.91      0.91        80\n",
            "weighted avg       0.91      0.91      0.91        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import Xception, ResNet152V2, InceptionResNetV2, DenseNet201, NASNetLarge\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Установка параметров\n",
        "img_height, img_width = 100, 100  # Размер изображений для моделей\n",
        "num_classes = 4\n",
        "batch_size = 32\n",
        "\n",
        "# Пути к данным\n",
        "nb_images = 700  # Количество изображений в каждой категории для обучения\n",
        "train_dir = f\"train_data_{nb_images}/train\"\n",
        "val_dir = f\"train_data_{nb_images}/val\"\n",
        "test_dir = \"test_data_1\"\n",
        "\n",
        "# Генераторы данных\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Создание и обучение моделей\n",
        "models = [Xception, ResNet152V2, InceptionResNetV2, DenseNet201, NASNetLarge]\n",
        "\n",
        "for model_type in models:\n",
        "    base_model = model_type(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(f\"\\nTraining {model_type.__name__}...\")\n",
        "    model.fit(train_generator, epochs=15, validation_data=val_generator)\n",
        "\n",
        "    # Оценка модели на тестовом наборе данных\n",
        "    print(f\"\\nEvaluating {model_type.__name__} on test data...\")\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    print(f\"Test Accuracy: {test_acc}\")\n",
        "\n",
        "    # Предсказания модели\n",
        "    predictions = model.predict(test_generator)\n",
        "    y_pred = np.argmax(predictions, axis=1)\n",
        "    y_true = test_generator.classes\n",
        "\n",
        "    # Матрица ошибок\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    # Метрики precision, recall и f1-score\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=test_generator.class_indices))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}